# habarovsk_hack
#### Данный репозиторий является решением "Кейс №1: Защита редких животных" от команды "ML Princess [Napoleon IT]"

### Содержание
- [user guide](#user-guide):
    * [Структура репозитория](#структура-репозитория)
    * [Инструкция по использованию репозитория в docker](#docker-run)
- [Объяснение решения](#объяснение-решения)


# User guide
### Структура репозитория
- [app](./app/) - папка содержащая реализацию бэка, всю логику работы моделей, инициализацию моделей
- [telebot](./telebot/) - папка содержащая реализацию бота, логику обработки ответов модели и их вывод пользователю
- [backend.py](backend.py) - вспомогательный файл для запуска сервиса
- [docker-compose.yml](docker-compose.yml) - конфиг докера для сборки и поднятия сервиса и бота с нужными портами и тд
- [Dockerfile](Dockerfile) - докер файл сервиса, отвечающий за окружение и установку нужных пакетов, библиотек
- [inference_model.py](inference.py) - скрипт для инференса моделей(прогон изображений через модели и составление csv таблицы с результатами работы)
- [requirements.txt](requirements.txt) - файл со всеми необходимыми библиотеками для работы сервиса
### Docker run
Для того чтобы поднять сервис на локальной/удаленной машине нужно:
- убедиться, что указанные порты в ```docker-compose.yml``` доступны на вашей машине
- запустить скрипт сборки docker контейнеров:
```
docker-compose build
```
- запустить скрипт поднятия сервисов:
```
docker-compose up
```
- Поздравляем, сервисы подняты
### Объяснение решения 
В сервисе используются 3 обученные модели:
1. Две каскадные модели для детекции животных
2. Визуальный трансформер ViT с ArcFace для классификации солодых и взрослых особей, найденных на предыдущем шаге

<!-- Данная ветка содержит реализацию сервиса с моделями детекции с использование ```MMdetection, Flask, Docker``` -->

## Описание решения 
Мы реализовали сервис с моделями детекции, который производит подсчет моржей на лежбище по принятым изображениям
Структурно наше решение можно представить следующим образом
```mermaid
graph TD
    A(Start Service) --> P[Images request] 
    P --> B[Preprocessing]
    B --> C[Detection Service]
    C --> D[HRNet model]
    C --> E[Cascade RCNN model]
    D --> F[sahi sliced detection]
    E --> J[sahi sliced detection]
    F --> K[Detection Ensemble]
    J --> K[Detection Ensemble]
    K --> Y[Draw contours]
    Y --> V[Save and Visualize]
    V --> X[Sum up the statistics]
    X --> Z(Send response)
```
### Подробное описание Detection Service
Мы провели ряд экспериментов с разными архитектурами и подходами в обучении моделей детекции. Одной из особенностей данной задачи является проблема детекции мелких объектов на ```high resolution``` изображениях. Подходы к решению данной проблемы рассмотрены в ряде статей:
- HRDNet: High-resolution Detection Network for Small Objects - https://arxiv.org/pdf/2006.07607.pdf
- Small Object Detection using Deep Learning - https://arxiv.org/pdf/2201.03243.pdf \
После изучения данной проблемы и полученных данных мы решили провести эксперименты и мы подсчитывали кастомную метрику:
```
Здесь будет формула для подсчета метрики
```
| model | method/arch  |
| :---: | :-: |
| Cascade + ResNet-50 | RFP  |
| Cascade + ResNet-50 | SAC  |
| Cascade R-CNN | HRNet  |
| FCOS | HRNet  |
| Faster R-CNN | FPN  |
| Yolo | V5  |
| Yolo | X  |

После анализа результатов мы приняли выбрали 2 модели, которые показали по нашей метрике лучшие результаты:
- CASCADE_RCNN_HRNET
    ![](examples/hrnet.png)
- CASCADE_RCNN \
    ![](examples/cascade_rcnn.png) 

Мы решили заняться тюнингом данных моделей для улучшения распознований, но к значительным изменениям это не привело, в следствии чего мы углубились в ресерч. \
Из статей мы вынесли основную мысль - мы хотим обученной моделью предиктить не сразу все изображение, а делать это определенным ```слайдом```. Данный механизм присутствует в библиотеке ```sahi``` ([ссылка на исходник](#https://github.com/obss/sahi)):
![](examples/sliced_inference.gif)
Данным механизмом мы улучшили наши метрики на ```30%```. В итоге мы решили полноценно внедрить данную технологию.

Как мы выяснили из экспериментов и статей:
- Модель ```HRNet``` хорошо работает на ```high resolution``` изображениях и хорошо детектит мелкие элементы
- Модель ```Cascade RCNN``` хорошо справляется с детекцией элементов на ближних изображениях

После данных наблюдений мы решили попробовать сделать ```ансамбль``` из данных моделей (в связке с ```sahi```) с неким усреднением ```bboxes``` с каждой модели - если кратко, то целью было брать объекты, которые нашла одна модель, а другая не справилась с этим.
По итогу мы механизмом ```ансамблирования``` лучших моделей мы улучшили качество на ```9%```. 
